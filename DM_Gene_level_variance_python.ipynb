{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from statsmodels import stats\n",
    "import statsmodels.stats.multitest as multi\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import ranksums\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import math\n",
    "import re\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn import linear_model\n",
    "from scipy.stats import ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell-type variability analysis\n",
    "# Distance to the Medoid analysis from Liu et al (2023)\n",
    "# \n",
    "# Code adopted from Liu et al. for Python implementation\n",
    "# github: https://github.com/jiayiliujiayi/scRNA_Seq-Differential_Variability_Analysis/\n",
    "# \n",
    "# Paper reference: \n",
    "# Liu, J., Kreimer, A. & Li, W. V. Differential variability analysis of\n",
    "# single-cell gene expression data. Brief. Bioinform. 24, (2023).\n",
    "\n",
    "\n",
    "# With Densne input. broken by cluster and genotype, get distances for each cell from every other cell.\n",
    "# Find the cell with minimum average distance to other cells, this cell is the medoid.\n",
    "# return list of distances of every cell from the medoid.\n",
    "def calc_DM(data):\n",
    "    #make array of sample vectors and all pairwise distances\n",
    "    vectors = data[[\"denSNE_1\",\"denSNE_2\"]].to_numpy()\n",
    "    dist_matrix = pairwise_distances(vectors, metric='euclidean')\n",
    "    \n",
    "    # find medoid\n",
    "    # cell with least distance to all cells\n",
    "    # each row is a cells distance to other cells\n",
    "    # so index with minimum sum is medoid\n",
    "    medoid_in = np.argmin(dist_matrix.sum(axis=0))\n",
    "    #row of medoid has distance of cells to medoid\n",
    "    DM = dist_matrix[medoid_in]\n",
    "    return DM\n",
    "\n",
    "# Run the full analysis.\n",
    "# Loop through all the clusters to get distance metrics for each genotype.\n",
    "# Perform wilcoxon rank sum test to compare distance metrics between genotype.\n",
    "# Correct for multiple comparison testing by BH FDR correction.\n",
    "def run_DM(data_d, data_n):\n",
    "    stats = []\n",
    "    ps = []\n",
    "    DM_D_average = []\n",
    "    DM_N_average = []\n",
    "    cluster_D_size = []\n",
    "    cluster_N_size = []\n",
    "    cluster = []\n",
    "    stds = []\n",
    "    for i in range(len(data_d)):\n",
    "        DM_d = calc_DM(data_d[i])\n",
    "        DM_n = calc_DM(data_n[i])\n",
    "        stds.append([np.std(DM_d)/math.sqrt(len(data_d[i])), np.std(DM_n)/math.sqrt(len(data_n[i]))])\n",
    "        #perform Wilcoxon rank sums test\n",
    "        stat, p = ranksums(DM_d, DM_n, alternative='two-sided')\n",
    "\n",
    "        stats.append(stat)\n",
    "        ps.append(p)\n",
    "        #DM_D_average.append(np.mean(DM_d))\n",
    "        #DM_N_average.append(np.mean(DM_n))\n",
    "        \n",
    "        DM_D_average.append(np.median(DM_d))\n",
    "        DM_N_average.append(np.median(DM_n))\n",
    "        \n",
    "        cluster_D_size.append(len(data_d[i]))\n",
    "        cluster_N_size.append(len(data_n[i]))\n",
    "        cluster.append(i)\n",
    "    f_results = pd.DataFrame({\"Cluster\":cluster,\n",
    "                              \"DM_average_Disease\":DM_D_average,\n",
    "                              \"DM_average_Normal\":DM_N_average,\n",
    "                              \"Cluster_Disease_Size\": cluster_D_size,\n",
    "                              \"Cluster_Normal_Size\": cluster_N_size,\n",
    "                              \"Stat\":stats,\n",
    "                              \"p\": ps})\n",
    "    p_adj = multi.fdrcorrection(ps)\n",
    "    f_results['Sig?'] = p_adj[0]\n",
    "    f_results['Adjusted P'] = p_adj[1]\n",
    "    return f_results, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in densne (output from R script) and meta data\n",
    "dense = pd.read_csv('filtered/all_matrix_data/densne_embeds/dense_ds_scrnaseq_NPCs.csv')\n",
    "meta = pd.read_csv('filtered/all_matrix_data/meta_data/meta_data_DS_scrnaseq_NPCS_2.csv')\n",
    "labels = meta['dx']\n",
    "clusters = meta['cca_clusters']   #choose whichever cluster from R analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine indicies of DS and normal cells\n",
    "down_indicies = np.asarray(labels == 'T21').nonzero()\n",
    "normal_indicies = np.asarray(labels == 'Euploid').nonzero()\n",
    "\n",
    "down_indicies, normal_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b46dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data into clusters by condition\n",
    "num_clus = len(pd.unique(clusters))\n",
    "data_d = []\n",
    "data_n = []\n",
    "for i in range(num_clus):\n",
    "    cluster_index = np.asarray(clusters == i).nonzero()\n",
    "    di = np.intersect1d(down_indicies, cluster_index)\n",
    "    ni = np.intersect1d(normal_indicies, cluster_index)\n",
    "    clus_d = dense.iloc[di]\n",
    "    clus_n = dense.iloc[ni]\n",
    "    data_d.append(clus_d)\n",
    "    data_n.append(clus_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e29d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run distance to the medoid analysis\n",
    "results, stds = run_DM(data_d, data_n)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba8dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gene-Level variance analysis\n",
    "# Method derived from Brennecke et al. and Osorio et al. \n",
    "# MATLAB code from  scGEAToolBox from sc_hvg function was modeled (Cai, 2019)\n",
    "# for Python implmentation\n",
    "# Github: https://github.com/jamesjcai/scGEAToolbox\n",
    "#\n",
    "# Paper References:\n",
    "# Brennecke, P. et al. Accounting for technical noise in single-cell RNA-seq experiments. \n",
    "# Nat. Methods 10, 1093–1095 (2013).\n",
    "#\n",
    "# Osorio, D. et al. Single-Cell Expression Variability Implies Cell Function. Cells 9, (2019).\n",
    "#\n",
    "# Cai, James J. 2019. “scGEAToolbox: A Matlab Toolbox for Single-Cell RNA Sequencing Data Analysis.” \n",
    "# Bioinformatics (Oxford, England) 36 (6): 1948–49.\n",
    "###################################################################\n",
    "# Input of counts matrix\n",
    "# return genes with at least 5% of cells expressing gene\n",
    "def filter_low_genes(df):\n",
    "    size = len(df)\n",
    "    threshold = int(size * 0.05)\n",
    "    #print(threshold)\n",
    "    ind = np.where(df.astype(bool).sum(axis=0) <= threshold)\n",
    "    return df.drop(df.columns[ind[0]],axis=1,inplace=False)\n",
    "\n",
    "# loop through both genotypes' data to filter for each cluster\n",
    "def filter_all(data_d, data_n):\n",
    "    d = []\n",
    "    n = []\n",
    "    for i in range(len(data_d)):\n",
    "        d.append(filter_low_genes(data_d[i]))\n",
    "        n.append(filter_low_genes(data_n[i]))\n",
    "    return d, n\n",
    "\n",
    "# Calculate the CV2, means for each gene.\n",
    "# loops through both genotype's dataframes\n",
    "def calc_metrics_filt(clusterd, clustern):\n",
    "    cvd=[]\n",
    "    cvn=[]\n",
    "    mean_d=[]\n",
    "    mean_n=[]\n",
    "    p=[]\n",
    "    for column in clusterd.columns:\n",
    "        countsd = np.array(clusterd[column])\n",
    "        meand = np.mean(countsd)\n",
    "        cv2d = np.var(countsd) / (meand**2)\n",
    "        cvd.append(cv2d)\n",
    "        mean_d.append(meand)\n",
    "    \n",
    "    for column in clustern.columns:\n",
    "        countsn = np.array(clustern[column])\n",
    "        meann = np.mean(countsn)\n",
    "        cv2n = np.var(countsn) / (meann**2)\n",
    "        cvn.append(cv2n)\n",
    "        mean_n.append(meann)\n",
    "    \n",
    "    f_results_d = pd.DataFrame({\"Gene\":clusterd.columns,\n",
    "                              \"CV2_DS\":cvd,\n",
    "                              \"Mean_DS\": mean_d})\n",
    "    f_results_n = pd.DataFrame({\"Gene\":clustern.columns,\n",
    "                              \"CV2_Nor\":cvn,\n",
    "                              \"Mean_Nor\": mean_n})\n",
    "    return f_results_d, f_results_n\n",
    "\n",
    "# Input of dataframe with calculated metrics following calc_metrics_filt()\n",
    "# and genotype, where true is DS. \n",
    "# Finds mean threshold where only 5% of genes present with CV2 greater than 0.3\n",
    "# are above this threshold. After filtering using this threshold, fit a linear model\n",
    "# following eq CV2{exp} = A1/mean + A0\n",
    "# returns fit and dataframe\n",
    "def fit_glm(t, ds):\n",
    "    if ds == True:\n",
    "        mean_dx = \"Mean_DS\"\n",
    "        cvs_dx = \"CV2_DS\"\n",
    "    else:\n",
    "        mean_dx = \"Mean_Nor\"\n",
    "        cvs_dx = \"CV2_Nor\"\n",
    "    # need to threshold and filter\n",
    "    t = t[t[mean_dx] != 0]\n",
    "\n",
    "    ds_hcv = t[t[cvs_dx] > 0.3]\n",
    "\n",
    "    #select threshold by geting mean such that\n",
    "    #only 5% of genes with cv>0.3 are above this\n",
    "    #threshold\n",
    "\n",
    "    ds_u_thresh = np.percentile(ds_hcv[mean_dx], 95)\n",
    "\n",
    "    t_filt = t[t[mean_dx] > ds_u_thresh]\n",
    " \n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(np.array(1/t_filt[mean_dx]).reshape(-1, 1),np.array(t_filt[cvs_dx]).reshape(-1, 1))\n",
    "    \n",
    "\n",
    "    return reg, t\n",
    "\n",
    "\n",
    "# input of linear models for both genotypes, and dataframes from both genotypes\n",
    "# Calculates the expected CV2 usiing model. Finds the residual and stores data\n",
    "# in each respective dataframe\n",
    "def calc_residuals(reg, regn, t, tn):\n",
    "    x = np.array(t['Mean_DS']).reshape(-1,1)\n",
    "    x2 = np.array(tn['Mean_Nor']).reshape(-1,1)\n",
    "    ypred = reg.predict(1/x)\n",
    "    ypred2 = regn.predict(1/x2)\n",
    "    t['CV2_DS_Exp'] = ypred\n",
    "    tn['CV2_Nor_Exp'] = ypred2\n",
    "    \n",
    "    t['DS_resid'] = np.array(t['CV2_DS']).reshape(-1,1) / ypred\n",
    "    tn['Nor_resid'] = np.array(tn['CV2_Nor']).reshape(-1,1) / ypred2\n",
    "\n",
    "# Input of datasets for each dataset\n",
    "# Residual sampling distribution approximates chi-squared distribution\n",
    "# Correct for multiple comparisons and save data in dataframes.\n",
    "def chi_distribution(t, tn, dfd, dfn):\n",
    "    ds_p = 1-chi2.cdf(t[\"DS_resid\"]*dfd, dfd)  #get the probability upper distribution\n",
    "    no_p = 1-chi2.cdf(tn[\"Nor_resid\"]*dfn, dfn)\n",
    "    noL_p = chi2.cdf(tn[\"Nor_resid\"]*dfn, dfn) # get the probability of lower distribution\n",
    "    dsL_p = chi2.cdf(t[\"DS_resid\"]*dfd, dfd)\n",
    "    \n",
    "    t['DS_chi_HVG'] = ds_p\n",
    "    tn['Nor_chi_HVG'] = no_p\n",
    "    t['DS_chi_sig'] = multi.fdrcorrection(ds_p)[0]\n",
    "    tn['Nor_chi_sig'] = multi.fdrcorrection(no_p)[0]\n",
    "    t['DS_chi_fdr'] = multi.fdrcorrection(ds_p)[1]\n",
    "    tn['Nor_chi_fdr'] = multi.fdrcorrection(no_p)[1]\n",
    "    \n",
    "    tn['Nor_chi_LVG'] = noL_p\n",
    "    t['DS_chi_LVG'] = dsL_p\n",
    "    t['DS_chi_sig_LVG'] = multi.fdrcorrection(dsL_p)[0]\n",
    "    tn['Nor_chi_sig_LVG'] = multi.fdrcorrection(noL_p)[0]\n",
    "    t['DS_chi_fdr_LVG'] = multi.fdrcorrection(dsL_p)[1]\n",
    "    tn['Nor_chi_fdr_LVG'] = multi.fdrcorrection(noL_p)[1]\n",
    "    \n",
    "# Run the full analysis after filtering input datasets\n",
    "# returns dataframe with gene-level metrics per genotype per cluster\n",
    "def run_full(down, normal):\n",
    "    all_results = []\n",
    "    for i in range(len(down)):\n",
    "        resd, resn = calc_metrics_filt(down[i], normal[i])\n",
    "        reg, resd = fit_glm(resd, True)\n",
    "        regn, resn = fit_glm(resn, False)\n",
    "        #reg, regn, res = fit_glm(res)\n",
    "        #print(res)\n",
    "        calc_residuals(reg,regn,resd, resn)\n",
    "        \n",
    "        dfd = len(down[0])-1\n",
    "        dfn = len(normal[0])-1\n",
    "        chi_distribution(resd, resn, dfd, dfn)\n",
    "        \n",
    "        \n",
    "        all_results.append((resd,resn))\n",
    "    return all_results\n",
    "\n",
    "# Returns significant HVG from dataframe\n",
    "def sig_results_HVG(results):\n",
    "    sig_results_d = []\n",
    "    sig_results_n = []\n",
    "\n",
    "    for j in range(len(results)):\n",
    "        resultd = results[j][0]\n",
    "        resultn = results[j][1]\n",
    "        sig_results_d.append(resultd[resultd['DS_chi_sig'] == True])\n",
    "        sig_results_n.append(resultn[resultn['Nor_chi_sig'] == True])\n",
    "    return sig_results_d, sig_results_n\n",
    "\n",
    "# Returns signficant LVG from dataframe\n",
    "def sig_resultsLVG(results):\n",
    "    sig_results_d = []\n",
    "    sig_results_n = []\n",
    "\n",
    "    for j in range(len(results)):\n",
    "        resultd = results[j][0]\n",
    "        resultn = results[j][1]\n",
    "        sig_results_d.append(resultd[resultd['DS_chi_sig_LVG'] == True])\n",
    "        sig_results_n.append(resultn[resultn['Nor_chi_sig_LVG'] == True])\n",
    "    return sig_results_d, sig_results_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e5442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "normalized_counts_d = pd.read_csv('filtered/all_matrix_data/deseq_counts/Deseq2_norm_DS_scrnaseq.csv')\n",
    "rows = pd.read_csv('filtered/all_matrix_data/gene_rows/genes_rows_DS_scrnaseq_NPCs.csv')\n",
    "normalized_counts_d.index = rows['x']\n",
    "normalized_counts_d = normalized_counts_d.T.iloc[1:,:]\n",
    "meta = pd.read_csv('filtered/all_matrix_data/meta_data/meta_data_DS_scrnaseq_NPCS_2.csv')\n",
    "labels = meta['dx']\n",
    "clusters = meta['cca_clusters']   #choose whichever cluster from R analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e471e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine indicies of DS and normal cells\n",
    "down_indicies = np.asarray(labels == 'T21').nonzero()\n",
    "normal_indicies = np.asarray(labels == 'Euploid').nonzero()\n",
    "\n",
    "#separate data into clusters by condition\n",
    "num_clus = len(pd.unique(clusters))\n",
    "data_d = []\n",
    "data_n = []\n",
    "for i in range(num_clus):\n",
    "    cluster_index = np.asarray(clusters == i).nonzero()\n",
    "    di = np.intersect1d(down_indicies, cluster_index)\n",
    "    ni = np.intersect1d(normal_indicies, cluster_index)\n",
    "    clus_d = normalized_counts_d.iloc[di]\n",
    "    clus_n = normalized_counts_d.iloc[ni]\n",
    "    data_d.append(clus_d)\n",
    "    data_n.append(clus_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae21870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the analysis\n",
    "data_df, data_nf = filter_all(data_d,data_n)\n",
    "ds_results = run_full(data_df, data_nf)\n",
    "ds_sig_results = sig_results_HVG(ds_results)\n",
    "ds_sig_results_LVG = sig_resultsLVG(ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388927b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save excel sheets by HVG and LVG separately\n",
    "with pd.ExcelWriter('DS_HVG_SCT_5.xlsx') as writer:\n",
    "    for i in range(len(ds_sig_results[0])):\n",
    "        ds_sig_results[0][i].to_excel(writer, sheet_name=\"down\"+\"_cluster_\"+str(i))\n",
    "        ds_sig_results[1][i].to_excel(writer, sheet_name=\"WT\"+\"_cluster_\"+str(i))\n",
    "with pd.ExcelWriter('DS_LVG_SCT_5.xlsx') as writer:\n",
    "    for i in range(len(ds_sig_results_LVG[0])):\n",
    "        ds_sig_results_LVG[0][i].to_excel(writer, sheet_name=\"down\"+\"_cluster_\"+str(i))\n",
    "        ds_sig_results_LVG[1][i].to_excel(writer, sheet_name=\"WT\"+\"_cluster_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121cef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save excel sheets per cluster with all genes, HVG and LVG\n",
    "# These files were used for subsequent analysis from gene_level_analyses.R\n",
    "xls = pd.ExcelFile('DS_HVG_SCT_5.xlsx')\n",
    "xls2 = pd.ExcelFile('DS_LVG_SCT_5.xlsx')\n",
    "for x in xls.sheet_names:\n",
    "    sheet = pd.read_excel(xls, x)\n",
    "    sheetL = pd.read_excel(xls2, x)\n",
    "\n",
    "    if len(sheet) == 0:\n",
    "        continue\n",
    "    \n",
    "    outfile = \"Variable_gene_lists/DS_scrnaseq_5/\"+ x + \".csv\"\n",
    "    #gene.to_csv(outfile, index=False, header=False)\n",
    "    if \"down\" in x:\n",
    "        #print(sheet['DS_resid'].median())\n",
    "        #cutoff = sheet['DS_resid'].quantile(0.25)\n",
    "        #sheet = sheet[sheet[\"DS_resid\"] > cutoff]\n",
    "        sheet[\"FDR\"] = sheet[\"DS_chi_fdr\"]\n",
    "        sheetL[\"FDR\"] = sheetL[\"DS_chi_fdr_LVG\"]\n",
    "    else:\n",
    "        #print(sheet['Nor_resid'].median())\n",
    "        #cutoff = sheet['Nor_resid'].quantile(0.25)\n",
    "        #sheet = sheet[sheet[\"Nor_resid\"] > cutoff]\n",
    "        sheet[\"FDR\"] = sheet[\"Nor_chi_fdr\"]\n",
    "        sheetL[\"FDR\"] = sheetL[\"Nor_chi_fdr_LVG\"]\n",
    "    \n",
    "\n",
    "    pd.concat([sheet, sheetL]).to_csv(outfile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
